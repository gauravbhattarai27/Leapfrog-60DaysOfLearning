{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKEmc9VIoWx3",
        "outputId": "de283c8a-1936-4250-fae2-4c693ea025b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.956140350877193\n",
            "Confusion Matrix:\n",
            " [[39  4]\n",
            " [ 1 70]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94        43\n",
            "           1       0.95      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ---\n",
        "\n",
        "# ### **1. Accuracy: `0.9561`**\n",
        "\n",
        "# * This means **95.61%** of the predictions made by your logistic regression model were correct.\n",
        "# * Out of 114 test cases, about **109** were predicted correctly.\n",
        "\n",
        "# ---\n",
        "\n",
        "# ### **2. Confusion Matrix**\n",
        "\n",
        "# ```\n",
        "# [[39  4]\n",
        "#  [ 1 70]]\n",
        "# ```\n",
        "\n",
        "# Here's how to read it:\n",
        "\n",
        "# |              | Predicted 0 | Predicted 1 |\n",
        "# | ------------ | ----------- | ----------- |\n",
        "# | **Actual 0** | 39          | 4           |\n",
        "# | **Actual 1** | 1           | 70          |\n",
        "\n",
        "# * **True Negatives (TN)** = 39 → Model correctly predicted 0 (no cancer)\n",
        "# * **False Positives (FP)** = 4 → Model wrongly predicted 1 when it was actually 0\n",
        "# * **False Negatives (FN)** = 1 → Model wrongly predicted 0 when it was actually 1\n",
        "# * **True Positives (TP)** = 70 → Model correctly predicted 1 (cancer)\n",
        "\n",
        "# ---\n",
        "\n",
        "# ###  **3. Classification Report**\n",
        "\n",
        "# This shows **precision**, **recall**, and **f1-score** for each class (0 and 1):\n",
        "\n",
        "# | Label             | Precision | Recall | F1-score | Support |\n",
        "# | ----------------- | --------- | ------ | -------- | ------- |\n",
        "# | **0** (no cancer) | 0.97      | 0.91   | 0.94     | 43      |\n",
        "# | **1** (cancer)    | 0.95      | 0.99   | 0.97     | 71      |\n",
        "\n",
        "# #### What these mean:\n",
        "\n",
        "# * **Precision**: Out of all predicted positives, how many were actually correct?\n",
        "\n",
        "#   * Class 0: 97% of the time, when model said \"no cancer\", it was right.\n",
        "#   * Class 1: 95% of the time, when model said \"cancer\", it was right.\n",
        "\n",
        "# * **Recall**: Out of all actual positives, how many did the model catch?\n",
        "\n",
        "#   * Class 0: 91% of actual \"no cancer\" cases were correctly identified.\n",
        "#   * Class 1: 99% of actual \"cancer\" cases were correctly identified.\n",
        "\n",
        "# * **F1-score**: Balance between precision and recall (good overall performance measure).\n",
        "\n",
        "# * **Support**: Number of samples for each class in test data\n",
        "#   (43 \"no cancer\", 71 \"cancer\")\n",
        "\n",
        "# ---\n",
        "\n",
        "# ### **4. Averages at the bottom**\n",
        "\n",
        "# | Metric Type   | Precision | Recall | F1-score |\n",
        "# | ------------- | --------- | ------ | -------- |\n",
        "# | **Macro avg** | 0.96      | 0.95   | 0.95     |\n",
        "# | **Weighted**  | 0.96      | 0.96   | 0.96     |\n",
        "\n",
        "# * **Macro avg** = Unweighted average (treats all classes equally)\n",
        "# * **Weighted avg** = Accounts for class imbalance (more samples of class 1)\n",
        "\n",
        "# ---\n",
        "\n",
        "# ###  Summary:\n",
        "\n",
        "# Your model is **performing very well**:\n",
        "\n",
        "# * High **accuracy (95.6%)**\n",
        "# * Almost perfect **recall (99%)** for detecting cancer\n",
        "# * Balanced **precision and recall**\n",
        "# * Slightly weaker on identifying \"no cancer\" (only 91% recall), but still strong\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QJTDhpsOodkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GxZPGfWAs3ni"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}